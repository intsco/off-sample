{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import Compose, JpegCompression, CLAHE, RandomRotate90, Transpose, ShiftScaleRotate, \\\n",
    "        Blur, OpticalDistortion, GridDistortion, HueSaturationValue, Flip, VerticalFlip\n",
    "\n",
    "import pretrainedmodels as pm\n",
    "\n",
    "from kekas import Keker, DataOwner, DataKek\n",
    "from kekas.transformations import Transformer, to_torch, normalize\n",
    "from kekas.metrics import accuracy\n",
    "from kekas.modules import Flatten, AdaptiveConcatPool2d\n",
    "from kekas.callbacks import Callback, Callbacks, DebuggerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('GS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23238, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_list = []\n",
    "for ds_path in data_path.iterdir():\n",
    "    for cl in ['on', 'off']:\n",
    "        for p in (ds_path / cl).iterdir():\n",
    "            row_list.append([str(p), ds_path.name, cl])\n",
    "\n",
    "ds_df = pd.DataFrame(row_list, columns=['fpath', 'group', 'label'])\n",
    "ds_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fpath</th>\n",
       "      <th>group</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GS/DESI quan_Swales/on/C21H43O6P+H.png</td>\n",
       "      <td>DESI quan_Swales</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GS/DESI quan_Swales/on/C4H7O8P+Na.png</td>\n",
       "      <td>DESI quan_Swales</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GS/DESI quan_Swales/on/C21H39O7P+H.png</td>\n",
       "      <td>DESI quan_Swales</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GS/DESI quan_Swales/on/C10H11NO3+Na.png</td>\n",
       "      <td>DESI quan_Swales</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GS/DESI quan_Swales/on/C24H40O4+Na.png</td>\n",
       "      <td>DESI quan_Swales</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     fpath             group label\n",
       "0   GS/DESI quan_Swales/on/C21H43O6P+H.png  DESI quan_Swales    on\n",
       "1    GS/DESI quan_Swales/on/C4H7O8P+Na.png  DESI quan_Swales    on\n",
       "2   GS/DESI quan_Swales/on/C21H39O7P+H.png  DESI quan_Swales    on\n",
       "3  GS/DESI quan_Swales/on/C10H11NO3+Na.png  DESI quan_Swales    on\n",
       "4   GS/DESI quan_Swales/on/C24H40O4+Na.png  DESI quan_Swales    on"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17442,), (11621,), (11617,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inds, other_inds = next(GroupKFold(n_splits=4).split(ds_df.fpath, groups=ds_df.group))\n",
    "valid_inds, test_inds = next(GroupKFold(n_splits=2).split(ds_df.fpath, groups=ds_df.group))\n",
    "train_inds.shape, valid_inds.shape, test_inds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kekas.transformations import Transformer, to_torch, normalize\n",
    "from torchvision import transforms\n",
    "\n",
    "# create train and val datasets using DataKek class - a pytorch Dataset that uses\n",
    "# pandas DataFrame as data source\n",
    "\n",
    "# at first we need to create a reader function that will define how image will be opened\n",
    "def reader_fn(i, row):\n",
    "    # it always gets i and row as parameters\n",
    "    # where i is an index of dataframe and row is a dataframes row\n",
    "    image = cv2.imread(row[\"fpath\"])\n",
    "    if row[\"label\"] == \"on\":\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "    return {\"image\": image, \"label\": label}\n",
    "\n",
    "\n",
    "# Then we should create transformations/augmentations\n",
    "# We will use awesome https://github.com/albu/albumentations library\n",
    "def augs(p=0.5):\n",
    "    return Compose([\n",
    "        CLAHE(),\n",
    "        RandomRotate90(),\n",
    "        Transpose(),\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.50, rotate_limit=15, p=.75),\n",
    "        Blur(blur_limit=3),\n",
    "        OpticalDistortion(),\n",
    "        GridDistortion(),\n",
    "        HueSaturationValue()\n",
    "    ], p=p)\n",
    "\n",
    "def get_transforms(dataset_key, size, p):\n",
    "    # we need to use a Transformer class to apply transformations to DataKeks elements\n",
    "    # dataset_key is an image key in dict returned by reader_fn\n",
    "    \n",
    "    PRE_TFMS = Transformer(dataset_key, lambda x: cv2.resize(x, (size, size)))\n",
    "\n",
    "    AUGS = Transformer(dataset_key, lambda x: augs()(image=x)[\"image\"])\n",
    "\n",
    "    NRM_TFMS = transforms.Compose([\n",
    "        Transformer(dataset_key, to_torch()),\n",
    "        Transformer(dataset_key, normalize())\n",
    "    ])\n",
    "    \n",
    "    train_tfms = transforms.Compose([PRE_TFMS, AUGS, NRM_TFMS])\n",
    "    val_tfms = transforms.Compose([PRE_TFMS, NRM_TFMS])  # because we don't want to augment val set yet\n",
    "    \n",
    "    return train_tfms, val_tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfms, val_tfms = get_transforms(\"image\", 224, 0.5)\n",
    "\n",
    "train_dk = DataKek(df=ds_df.iloc[train_inds], reader_fn=reader_fn, transforms=train_tfms)\n",
    "val_dk = DataKek(df=ds_df.iloc[valid_inds], reader_fn=reader_fn, transforms=val_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and DataLoaders\n",
    "batch_size = 32\n",
    "workers = 8\n",
    "\n",
    "train_dl = DataLoader(train_dk, batch_size=batch_size, num_workers=workers, shuffle=True, drop_last=True)\n",
    "val_dl = DataLoader(val_dk, batch_size=batch_size, num_workers=workers, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple neural network using pretrainedmodels library\n",
    "# https://github.com/Cadene/pretrained-models.pytorch\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_classes: int,\n",
    "            p: float = 0.5,\n",
    "            pooling_size: int = 2,\n",
    "            last_conv_size: int = 2048,\n",
    "            arch: str = \"se_resnext50_32x4d\",\n",
    "            pretrained: str = \"imagenet\") -> None:\n",
    "        \"\"\"A simple model to finetune\n",
    "        \n",
    "        Args:\n",
    "            num_classes: the number of target classes, the size of the last layer's output\n",
    "            p: dropout probability\n",
    "            pooling_size: the size of the result feature map after adaptive pooling layer\n",
    "            last_conv_size: size of the flatten last backbone conv layer\n",
    "            arch: the name of the architecture form pretrainedmodels\n",
    "            pretrained: the mode for pretrained model from pretrainedmodels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        net = pm.__dict__[arch](pretrained=pretrained)\n",
    "        modules = list(net.children())[:-2]  # delete last layers: pooling and linear\n",
    "        \n",
    "        # add custom head\n",
    "        modules += [nn.Sequential(\n",
    "            # AdaptiveConcatPool2d is a concat of AdaptiveMaxPooling and AdaptiveAveragePooling \n",
    "            AdaptiveConcatPool2d(size=pooling_size),\n",
    "            Flatten(),\n",
    "            nn.BatchNorm1d(2 * pooling_size * pooling_size * last_conv_size),\n",
    "            nn.Dropout(p),\n",
    "            nn.Linear(2 * pooling_size * pooling_size * last_conv_size, num_classes)\n",
    "        )]\n",
    "        self.net = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.net(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [s for s in list(pm.__dict__) if not s.startswith('__')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pm.__dict__['resnet34']()\n",
    "modules = list(model.children())\n",
    "len(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pm.__dict__['se_resnext50_32x4d']()\n",
    "modules = list(model.children())[:-2]\n",
    "len(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the three whales of your pipelane are: the data, the model and the loss (hi, Jeremy)\n",
    "\n",
    "# the data is represented in Kekas by DataOwner. It is a namedtuple with three fields:\n",
    "# 'train_dl', 'val_dl', 'test_dl'\n",
    "# For training process we will need at least two of them, and we can skip 'test_dl' for now\n",
    "# so we will initialize it with `None` value.\n",
    "dataowner = DataOwner(train_dl, val_dl, None)\n",
    "\n",
    "# model is just a pytorch nn.Module, that we created vefore\n",
    "model = Net(num_classes=2, arch='resnet34', last_conv_size=512)\n",
    "\n",
    "# loss or criterion is also a pytorch nn.Module. For multiloss scenarios it can be a list of nn.Modules\n",
    "# for our simple example let's use the standart cross entopy criterion\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also we need to specify, what model will do with each batch of data on each iteration\n",
    "# We should define a `step_fn` function\n",
    "# The code below repeats a `keker.default_step_fn` code to provide you with a concept of step function\n",
    "\n",
    "def step_fn(model: torch.nn.Module,\n",
    "            batch: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Determine what your model will do with your data.\n",
    "\n",
    "    Args:\n",
    "        model: the pytorch module to pass input in\n",
    "        batch: the batch of data from the DataLoader\n",
    "\n",
    "    Returns:\n",
    "        The models forward pass results\n",
    "    \"\"\"\n",
    "    \n",
    "    # you could define here whatever logic you want\n",
    "    inp = batch[\"image\"]  # here we get an \"image\" from our dataset\n",
    "    return model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous preparations was mostly out of scope of Kekas library (except DataKeks creation)\n",
    "# Now let's dive into kekas a little bit\n",
    "\n",
    "# firstly, we create a Keker - the core Kekas class, that provides all the keks for your pipeline\n",
    "keker = Keker(model=model,\n",
    "              dataowner=dataowner,\n",
    "              criterion=nn.CrossEntropyLoss(),\n",
    "              step_fn=step_fn,                    # previosly defined step function\n",
    "              target_key=\"label\",                 # remember, we defined it in the reader_fn for DataKek?\n",
    "              metrics={\"acc\": accuracy},          # optional, you can not specify any metrics at all\n",
    "              opt=torch.optim.Adam,               # optimizer class. if not specifying, \n",
    "                                                  # the SGD is used by default\n",
    "              opt_params={\"weight_decay\": 1e-5},\n",
    "              device=device)  # optimizer kwargs in dict format (optional too)\n",
    "\n",
    "# Actually, there are a lot of params for kekers, but this out of scope of this example\n",
    "# you can read about them in Keker's docstring (but who really reads the docs, huh?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before the start of the finetuning procedure let's freeeze all the layers except the last one - the head\n",
    "# the `freeze` method is mostly inspired (or stolen) from fastai\n",
    "# but you should define a model's attribute to deal with\n",
    "# for example, our model is actually model.net, so we need to specify the 'net' attr\n",
    "# also this method does not freezes batchnorm layers by default. To change this set `freeze_bn=True`\n",
    "keker.freeze(model_attr=\"net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find an 'optimal' learning rate with learning rate find procedure\n",
    "# for details please see the fastai course and this articles:\n",
    "# https://arxiv.org/abs/1803.09820\n",
    "# https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html\n",
    "\n",
    "# NOTE: this is an optional step and you can skip it and use your favorite learning rate\n",
    "\n",
    "# you MUST specify the logdir to see graphics\n",
    "# keker will write a tensorboard logs into this folder\n",
    "# to see them start a tensorboard with `--logdir /path/to/logdir`\n",
    "\n",
    "# keker.kek_lr(final_lr=0.1, logdir=\"/tmp/tensorboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100% 545/545 [00:39<00:00, 13.81it/s, loss=0.2082, val_loss=0.0833, acc=0.9711]\n",
      "Epoch 2/5: 100% 545/545 [00:38<00:00, 19.75it/s, loss=0.1519, val_loss=0.0581, acc=0.9803]\n",
      "Epoch 3/5: 100% 545/545 [00:38<00:00, 19.90it/s, loss=0.0969, val_loss=0.0510, acc=0.9837]\n",
      "Epoch 4/5: 100% 545/545 [00:38<00:00, 14.03it/s, loss=0.1345, val_loss=0.0444, acc=0.9858]\n",
      "Epoch 5/5: 100% 545/545 [00:39<00:00, 13.95it/s, loss=0.0950, val_loss=0.0425, acc=0.9873]\n"
     ]
    }
   ],
   "source": [
    "lr = 5e-4\n",
    "epochs = 5\n",
    "keker.kek_one_cycle(max_lr=lr,                  # the maximum learning rate\n",
    "                    cycle_len=epochs,           # number of epochs, actually, but not exactly\n",
    "                    momentum_range=(0.95, 0.85),  # range of momentum changes\n",
    "                    div_factor=25,                # max_lr / min_lr\n",
    "                    increase_fraction=0.3)        # the part of cycle when learning rate increases\n",
    "\n",
    "# If you don't understand these parameters, read this - https://sgugger.github.io/the-1cycle-policy.html\n",
    "# NOTE: you cannot use schedulers and early stopping with one cycle!\n",
    "# another options are the same as for `kek` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dk = DataKek(df=ds_df.iloc[test_inds], reader_fn=reader_fn, transforms=val_tfms)\n",
    "test_dl = DataLoader(test_dk, batch_size=batch_size, num_workers=workers, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: 100% 364/364 [00:09<00:00, 37.01it/s]\n"
     ]
    }
   ],
   "source": [
    "test_outputs = keker.predict_loader(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = (torch.sigmoid(torch.from_numpy(test_outputs[:,1])) > 0.5).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_classes = np.array([row[1].label == 'off' for row in test_dk.data], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866574847206679"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_classes == test_preds).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keker.kek(lr=1e-5,\n",
    "#           epochs=5,\n",
    "#           opt=torch.optim.Adam,\n",
    "#           opt_params={\"weight_decay\": 1e-5},\n",
    "#           sched=torch.optim.lr_scheduler.StepLR,\n",
    "#           sched_params={\"step_size\":1, \"gamma\": 0.9},\n",
    "#           logdir=\"/path/to/logdir\",\n",
    "#           cp_saver_params={\n",
    "#               \"savedir\": \"/path/to/save/dir\",  \n",
    "#               \"metric\": \"acc\",  \n",
    "#               \"n_best\": 3,      \n",
    "#               \"prefix\": \"kek\",  \n",
    "#               \"mode\": \"max\"},     \n",
    "#           early_stop_params={\n",
    "#               \"patience\": 3,   \n",
    "#               \"metric\": \"acc\", \n",
    "#               \"mode\": \"min\",   \n",
    "#               \"min_delta\": 0\n",
    "#           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
